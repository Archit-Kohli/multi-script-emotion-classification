{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":106828,"databundleVersionId":12928713,"sourceType":"competition"},{"sourceId":282742,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239467,"modelId":222398}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multi-Script Emotion Classification using Gemma-3","metadata":{}},{"cell_type":"markdown","source":"## Importing Modules","metadata":{}},{"cell_type":"code","source":"!pip install -U trl\n!pip install -U bitsandbytes\n!pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T04:33:43.945652Z","iopub.execute_input":"2025-07-07T04:33:43.945820Z","iopub.status.idle":"2025-07-07T04:35:32.765607Z","shell.execute_reply.started":"2025-07-07T04:33:43.945803Z","shell.execute_reply":"2025-07-07T04:35:32.764845Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting trl\n  Downloading trl-0.19.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.5.2)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.6.0)\nRequirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.51.3)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.31.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (0.21.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=1.4.0->trl) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate>=1.4.0->trl)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate>=1.4.0->trl)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate>=1.4.0->trl)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate>=1.4.0->trl)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate>=1.4.0->trl)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate>=1.4.0->trl)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=1.4.0->trl) (2024.2.0)\nDownloading trl-0.19.0-py3-none-any.whl (375 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.19.0\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.46.1\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nCollecting wandb\n  Downloading wandb-0.21.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nDownloading wandb-0.21.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.19.9\n    Uninstalling wandb-0.19.9:\n      Successfully uninstalled wandb-0.19.9\nSuccessfully installed wandb-0.21.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import Dataset\nimport pandas as pd\nimport numpy as np\nimport kagglehub\nimport torch\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:19:49.141219Z","iopub.execute_input":"2025-07-07T07:19:49.141693Z","iopub.status.idle":"2025-07-07T07:19:49.145593Z","shell.execute_reply.started":"2025-07-07T07:19:49.141668Z","shell.execute_reply":"2025-07-07T07:19:49.144827Z"}},"outputs":[],"execution_count":119},{"cell_type":"markdown","source":"## Loading the Gemma Model","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    print(\"CUDA cache emptied.\")\nelse:\n    print(\"CUDA is not available, no cache to empty.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:19:52.981285Z","iopub.execute_input":"2025-07-07T07:19:52.981525Z","iopub.status.idle":"2025-07-07T07:19:52.987335Z","shell.execute_reply.started":"2025-07-07T07:19:52.981508Z","shell.execute_reply":"2025-07-07T07:19:52.986697Z"}},"outputs":[{"name":"stdout","text":"CUDA cache emptied.\n","output_type":"stream"}],"execution_count":120},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers.models.gemma3 import Gemma3ForCausalLM\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nGEMMA_PATH = kagglehub.model_download(\"google/gemma-3/transformers/gemma-3-1b-it\")\n\ntokenizer = AutoTokenizer.from_pretrained(\n    GEMMA_PATH,\n    max_seq_length=1024, #Ensure matches with trainer\n)\nmodel = Gemma3ForCausalLM.from_pretrained(\n    GEMMA_PATH,\n    attn_implementation=\"eager\",\n    low_cpu_mem_usage=True,\n    device_map=\"auto\"\n)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:23:51.905748Z","iopub.execute_input":"2025-07-07T07:23:51.905986Z","iopub.status.idle":"2025-07-07T07:23:55.797825Z","shell.execute_reply.started":"2025-07-07T07:23:51.905969Z","shell.execute_reply":"2025-07-07T07:23:55.797092Z"}},"outputs":[{"name":"stdout","text":"Gemma3ForCausalLM(\n  (model): Gemma3TextModel(\n    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 1152, padding_idx=0)\n    (layers): ModuleList(\n      (0-25): 26 x Gemma3DecoderLayer(\n        (self_attn): Gemma3Attention(\n          (q_proj): Linear(in_features=1152, out_features=1024, bias=False)\n          (k_proj): Linear(in_features=1152, out_features=256, bias=False)\n          (v_proj): Linear(in_features=1152, out_features=256, bias=False)\n          (o_proj): Linear(in_features=1024, out_features=1152, bias=False)\n          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n        )\n        (mlp): Gemma3MLP(\n          (gate_proj): Linear(in_features=1152, out_features=6912, bias=False)\n          (up_proj): Linear(in_features=1152, out_features=6912, bias=False)\n          (down_proj): Linear(in_features=6912, out_features=1152, bias=False)\n          (act_fn): PytorchGELUTanh()\n        )\n        (input_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n        (post_attention_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n        (pre_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n        (post_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n      )\n    )\n    (norm): Gemma3RMSNorm((1152,), eps=1e-06)\n    (rotary_emb): Gemma3RotaryEmbedding()\n    (rotary_emb_local): Gemma3RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1152, out_features=262144, bias=False)\n)\n","output_type":"stream"}],"execution_count":130},{"cell_type":"code","source":"def count_trainable_parameters(model):\n    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    return params\n\ncount_trainable_parameters(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:20:39.886738Z","iopub.execute_input":"2025-07-07T07:20:39.887001Z","iopub.status.idle":"2025-07-07T07:20:39.899103Z","shell.execute_reply.started":"2025-07-07T07:20:39.886980Z","shell.execute_reply":"2025-07-07T07:20:39.898337Z"}},"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"999885952"},"metadata":{}}],"execution_count":122},{"cell_type":"markdown","source":"## Inference using Gemma","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"<start_of_turn>user\nClassify sentence to one (and only one) of these emotions: [\"disgust\",\"anger\",\"sad\",\"happy\",\"fear\",\"surprise\"]. Just give one word answer. Even if you find multiple emotions, choose the best one! \nSentence: \"I'm very scared for my life, I don't know what to do next!\" <end_of_turn>\n<start_of_turn>model\"\"\"\n\ninput_ids = tokenizer(text=prompt, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(**input_ids, max_new_tokens=4)\ntext = tokenizer.batch_decode(\n    outputs,\n    skip_special_tokens=False,\n    clean_up_tokenization_spaces=False\n)\nprint(text[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:20:42.163851Z","iopub.execute_input":"2025-07-07T07:20:42.164213Z","iopub.status.idle":"2025-07-07T07:20:42.495558Z","shell.execute_reply.started":"2025-07-07T07:20:42.164190Z","shell.execute_reply":"2025-07-07T07:20:42.494922Z"}},"outputs":[{"name":"stdout","text":"<bos><start_of_turn>user\nClassify sentence to one (and only one) of these emotions: [\"disgust\",\"anger\",\"sad\",\"happy\",\"fear\",\"surprise\"]. Just give one word answer. Even if you find multiple emotions, choose the best one! \nSentence: \"I'm very scared for my life, I don't know what to do next!\" <end_of_turn>\n<start_of_turn>model\nFear<end_of_turn>\n\n","output_type":"stream"}],"execution_count":123},{"cell_type":"markdown","source":"## Preprocessing Dataset","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/emoti-code-multi-script-emotion-classification-rel/competition_train.csv')\nval_data = pd.read_csv('/kaggle/input/emoti-code-multi-script-emotion-classification-rel/competition_val.csv')\n\ny_true_val = val_data['emotion']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:20:45.651652Z","iopub.execute_input":"2025-07-07T07:20:45.652190Z","iopub.status.idle":"2025-07-07T07:20:45.710863Z","shell.execute_reply.started":"2025-07-07T07:20:45.652168Z","shell.execute_reply":"2025-07-07T07:20:45.710026Z"}},"outputs":[],"execution_count":124},{"cell_type":"code","source":"examples = {\n    \"Kashmiri\": train_data[train_data[\"language\"]==\"Kashmiri\"].sample(3),\n    \"Manipuri\": train_data[train_data[\"language\"]==\"Manipuri\"].sample(3),\n    \"Santali\": train_data[train_data[\"language\"]==\"Santali\"].sample(3)\n}\n\nkashmiri_prompt = \"\"\nfor i in range(3):\n    x = examples[\"Kashmiri\"].iloc[i]\n    kashmiri_prompt += f\"\"\"<start_of_turn>user\n    Classify sentence to exactly one of these emotions: [\"disgust\",\"anger\",\"sad\",\"happy\",\"fear\",\"surprise\"]. Just give one word answer. \n    Sentence: \"{x[\"Sentence\"]}\" \n    <end_of_turn>\n    <start_of_turn>model\n    {x[\"emotion\"]}\n    <end_of_turn>\\n\"\"\"\n\nmanipuri_prompt = \"\"\nfor i in range(3):\n    x = examples[\"Manipuri\"].iloc[i]\n    manipuri_prompt += f\"\"\"<start_of_turn>user\n    Classify sentence to exactly one of these emotions: [\"disgust\",\"anger\",\"sad\",\"happy\",\"fear\",\"surprise\"]. Just give one word answer. \n    Sentence: \"{x[\"Sentence\"]}\" \n    <end_of_turn>\n    <start_of_turn>model\n    {x[\"emotion\"]}\n    <end_of_turn>\\n\"\"\"\n\nsantali_prompt = \"\"\nfor i in range(3):\n    x = examples[\"Santali\"].iloc[i]\n    santali_prompt += f\"\"\"<start_of_turn>user\n    Classify sentence to exactly one of these emotions: [\"disgust\",\"anger\",\"sad\",\"happy\",\"fear\",\"surprise\"]. Just give one word answer. \n    Sentence: \"{x[\"Sentence\"]}\" \n    <end_of_turn>\n    <start_of_turn>model\n    {x[\"emotion\"]}\n    <end_of_turn>\\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:23:12.190541Z","iopub.execute_input":"2025-07-07T07:23:12.191268Z","iopub.status.idle":"2025-07-07T07:23:12.203627Z","shell.execute_reply.started":"2025-07-07T07:23:12.191237Z","shell.execute_reply":"2025-07-07T07:23:12.202916Z"}},"outputs":[],"execution_count":126},{"cell_type":"code","source":"def generate_train_prompt(x):\n    return f\"\"\"<start_of_turn>user\n    Classify sentence to exactly one of these emotions: [\"disgust\",\"anger\",\"sad\",\"happy\",\"fear\",\"surprise\"]. Just give one word answer. \n    Sentence: \"{x[\"Sentence\"]}\" \n    <end_of_turn>\n    <start_of_turn>model\n    {x[\"emotion\"]}\n    <end_of_turn>\"\"\"\n\ndef generate_val_prompt(x):\n    if x[\"language\"] == \"Kashmiri\":\n        prompt = kashmiri_prompt\n    if x[\"language\"] == \"Santali\":\n        prompt = santali_prompt\n    if x[\"language\"] == \"Manipuri\":\n        prompt = manipuri_prompt\n    return prompt+f\"\"\"<start_of_turn>user\n    You are an expert in {x[\"language\"]} language. Based on your understanding of the \"meaning\" of the given sentence, classify this sentence to exactly one of these emotions: [\"disgust\",\"anger\",\"sad\",\"happy\",\"fear\",\"surprise\"]. Just give one word answer, focus on the actual intention of the sentence and classify it properly. \n    Sentence: \"{x[\"Sentence\"]}\" \n    <end_of_turn>\n    <start_of_turn>model\n    \"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:23:23.572216Z","iopub.execute_input":"2025-07-07T07:23:23.572756Z","iopub.status.idle":"2025-07-07T07:23:23.577848Z","shell.execute_reply.started":"2025-07-07T07:23:23.572729Z","shell.execute_reply":"2025-07-07T07:23:23.577098Z"}},"outputs":[],"execution_count":127},{"cell_type":"code","source":"train_data = pd.DataFrame(train_data.apply(generate_train_prompt,axis=1),columns=[\"text\"])\nval_data_for_scoring = pd.DataFrame(val_data.apply(generate_val_prompt,axis=1),columns=[\"text\"])\nval_data = pd.DataFrame(val_data.apply(generate_train_prompt,axis=1),columns=[\"text\"])[:400]\n\nX_train = Dataset.from_pandas(train_data)\nX_eval = Dataset.from_pandas(val_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:23:35.738885Z","iopub.execute_input":"2025-07-07T07:23:35.739408Z","iopub.status.idle":"2025-07-07T07:23:35.865649Z","shell.execute_reply.started":"2025-07-07T07:23:35.739380Z","shell.execute_reply":"2025-07-07T07:23:35.865102Z"}},"outputs":[],"execution_count":128},{"cell_type":"code","source":"tokenizer(val_data_for_scoring.iloc[4]['text'],return_tensors=\"pt\")['input_ids'].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:23:39.551842Z","iopub.execute_input":"2025-07-07T07:23:39.552207Z","iopub.status.idle":"2025-07-07T07:23:39.559723Z","shell.execute_reply.started":"2025-07-07T07:23:39.552184Z","shell.execute_reply":"2025-07-07T07:23:39.559025Z"}},"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 492])"},"metadata":{}}],"execution_count":129},{"cell_type":"markdown","source":"## Processing and Evaluating Model Output","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\ndef evaluate(y_true,y_pred):\n    label_mapping = {\"disgust\":0,\"anger\":1,\"sad\":2,\"happy\":3,\"fear\":4,\"surprise\":5}\n    \n    y_true = np.array([label_mapping[label] for label in y_true])\n    y_pred = np.array([label_mapping[label] for label in y_pred])\n    \n    accuracy = accuracy_score(y_true, y_pred)\n    print(\"Overall Accuracy: \", accuracy)\n\n    # Label wise accuracy\n    unique_labels = np.unique(y_true)\n    for label in unique_labels:\n        label_mask = y_true == label\n        label_accuracy = accuracy_score(y_true[label_mask], y_pred[label_mask])\n        print(\"Accuracy for label \", label, \": \", label_accuracy)\n    \n    class_report = classification_report(y_true, y_pred, target_names=label_mapping.keys())\n    print('\\nClassification Report:\\n', class_report)\n    \n    conf_matrix = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3, 4, 5])\n    print('\\nConfusion Matrix:\\n', conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:23:58.935797Z","iopub.execute_input":"2025-07-07T07:23:58.936395Z","iopub.status.idle":"2025-07-07T07:23:58.942309Z","shell.execute_reply.started":"2025-07-07T07:23:58.936372Z","shell.execute_reply":"2025-07-07T07:23:58.941642Z"}},"outputs":[],"execution_count":131},{"cell_type":"code","source":"from tqdm import tqdm\n\nmax_new_tokens = 4\ntemperature = 0.2\n\ndef predict(X_test, model, tokenizer):\n    y_pred = []\n    for i in tqdm(range(len(X_test)), desc=\"Predicting Sentiments\"):\n        prompt = X_test.iloc[i][\"text\"]\n        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n        outputs = model.generate(\n            **input_ids, \n            max_new_tokens=max_new_tokens, \n            do_sample=True,\n            temperature=temperature\n        )\n        result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip().lower()\n        result = result.split(\"model\")[4]\n        if \"disgust\" in result:\n            y_pred.append(\"disgust\")\n        elif \"anger\" in result:\n            y_pred.append(\"anger\")\n        elif \"sad\" in result:\n            y_pred.append(\"sad\")\n        elif \"happy\" in result:\n            y_pred.append(\"happy\")\n        elif \"fear\" in result:\n            y_pred.append(\"fear\")\n        elif \"surprise\" in result:\n            y_pred.append(\"surprise\")\n        else:\n            y_pred.append(\"none\")\n\n    return y_pred\n\ndef predict_for_submission(X_test, model, tokenizer):\n    predictions = []\n    for i in tqdm(range(len(X_test)), desc=\"Predicting Sentiments for Submission\"):\n        entry_id = X_test.iloc[i][\"id\"]\n        prompt = X_test.iloc[i][\"text\"]\n        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n        model.eval()\n        with torch.no_grad():  \n            outputs = model.generate(\n                **input_ids,\n                max_new_tokens=max_new_tokens,\n                do_sample=True,\n                temperature=temperature\n            )\n        result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip().lower()\n        result = result.split(\"model\")[4]\n\n        predicted_emotion = \"happy\"\n        if \"disgust\" in result:\n            predicted_emotion = \"disgust\"\n        elif \"anger\" in result:\n            predicted_emotion = \"anger\"\n        elif \"sad\" in result:\n            predicted_emotion = \"sad\"\n        elif \"happy\" in result:\n            predicted_emotion = \"happy\"\n        elif \"fear\" in result:\n            predicted_emotion = \"fear\"\n        elif \"surprise\" in result:\n            predicted_emotion = \"surprise\"\n\n        predictions.append({\"id\": entry_id, \"emotion\": predicted_emotion})\n\n    submission_df = pd.DataFrame(predictions)\n    return submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:24:03.060190Z","iopub.execute_input":"2025-07-07T07:24:03.060468Z","iopub.status.idle":"2025-07-07T07:24:03.070333Z","shell.execute_reply.started":"2025-07-07T07:24:03.060448Z","shell.execute_reply":"2025-07-07T07:24:03.069602Z"}},"outputs":[],"execution_count":132},{"cell_type":"code","source":"y_pred_val = predict(val_data_for_scoring[:100], model, tokenizer)\nevaluate(y_true_val[:100],y_pred_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T08:36:54.948728Z","iopub.execute_input":"2025-07-07T08:36:54.949002Z","iopub.status.idle":"2025-07-07T08:38:07.275658Z","shell.execute_reply.started":"2025-07-07T08:36:54.948980Z","shell.execute_reply":"2025-07-07T08:38:07.274656Z"}},"outputs":[{"name":"stderr","text":"Predicting Sentiments: 100%|██████████| 100/100 [01:12<00:00,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Overall Accuracy:  0.36\nAccuracy for label  0 :  0.3\nAccuracy for label  1 :  0.2631578947368421\nAccuracy for label  2 :  0.15789473684210525\nAccuracy for label  3 :  0.5294117647058824\nAccuracy for label  4 :  0.7\nAccuracy for label  5 :  0.13333333333333333\n\nClassification Report:\n               precision    recall  f1-score   support\n\n     disgust       0.10      0.30      0.15        10\n       anger       0.38      0.26      0.31        19\n         sad       0.43      0.16      0.23        19\n       happy       0.56      0.53      0.55        17\n        fear       0.48      0.70      0.57        20\n    surprise       0.50      0.13      0.21        15\n\n    accuracy                           0.36       100\n   macro avg       0.41      0.35      0.34       100\nweighted avg       0.43      0.36      0.36       100\n\n\nConfusion Matrix:\n [[ 3  3  2  0  1  1]\n [ 7  5  2  1  4  0]\n [ 7  3  3  2  4  0]\n [ 5  0  0  9  2  1]\n [ 4  0  0  2 14  0]\n [ 5  2  0  2  4  2]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":151},{"cell_type":"markdown","source":"## Finetuning the model","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, PeftConfig, PeftModel\nfrom kaggle_secrets import UserSecretsClient\nfrom trl import SFTTrainer, SFTConfig\nimport bitsandbytes as bnb\nimport wandb\n\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\npeft_config = LoraConfig(\n    lora_alpha=32,\n    lora_dropout=0.05,\n    r=2,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\", \"down_proj\"],\n)\n\nwandb.login(key=api_key)\n\ntraining_arguments = SFTConfig(\n    output_dir=\"checkpoints_run_5\",\n    num_train_epochs=1,\n    gradient_checkpointing=True, \n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_8bit\", \n    save_steps=15,\n    logging_steps=15,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=True,\n    max_grad_norm=0.3, \n    warmup_ratio=0.03, \n    lr_scheduler_type=\"constant\",\n    report_to=\"wandb\",\n    max_seq_length=1024,\n    dataset_kwargs={\n        \"add_special_tokens\": False,\n        \"append_concat_token\": True, \n    },\n    label_names=[\"labels\"],\n    average_tokens_across_devices=False,\n    load_best_model_at_end=False,\n    eval_strategy=\"steps\",\n    per_device_eval_batch_size=2,\n    eval_steps=15,\n    eval_accumulation_steps=1,\n)\n\nwandb.init(\n    project=\"dlp_nppe1_gemma_3\",\n    entity=\"architkohli-msit\",\n    name=\"gemma-1b-lora-run-8\",\n    config=training_arguments.to_dict()\n)\nwandb.config.update(peft_config.to_dict())\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=X_train,\n    eval_dataset=X_eval,\n    peft_config=peft_config,\n    processing_class=tokenizer,\n    args=training_arguments\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:54:20.423508Z","iopub.execute_input":"2025-07-07T07:54:20.424164Z","iopub.status.idle":"2025-07-07T07:54:32.561077Z","shell.execute_reply.started":"2025-07-07T07:54:20.424142Z","shell.execute_reply":"2025-07-07T07:54:32.560562Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing previous runs because reinit is set to 'default'."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mean_token_accuracy</td><td>▁▅▆▆▇▇▇▇▇███████</td></tr><tr><td>eval/num_tokens</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>eval/runtime</td><td>▁▅▆█▆▅▆▄▄▆▆▄▅▆█▇</td></tr><tr><td>eval/samples_per_second</td><td>█▄▃▁▂▄▃▅▅▃▃▅▄▃▁▂</td></tr><tr><td>eval/steps_per_second</td><td>█▄▃▁▂▄▃▅▅▃▃▅▄▃▁▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▄▃▃▂▁▂▁▁▂▁▂▁▁▁▂</td></tr><tr><td>train/learning_rate</td><td>▁████████▇▇▇▇▇▆▆</td></tr><tr><td>train/loss</td><td>█▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/mean_token_accuracy</td><td>▁▅▆▇▇▇▇█████████</td></tr><tr><td>train/num_tokens</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.15109</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.71123</td></tr><tr><td>eval/num_tokens</td><td>337420</td></tr><tr><td>eval/runtime</td><td>32.2232</td></tr><tr><td>eval/samples_per_second</td><td>12.413</td></tr><tr><td>eval/steps_per_second</td><td>6.207</td></tr><tr><td>train/epoch</td><td>0.26756</td></tr><tr><td>train/global_step</td><td>240</td></tr><tr><td>train/grad_norm</td><td>1.30033</td></tr><tr><td>train/learning_rate</td><td>0.00017</td></tr><tr><td>train/loss</td><td>1.1088</td></tr><tr><td>train/mean_token_accuracy</td><td>0.71056</td></tr><tr><td>train/num_tokens</td><td>337420</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gemma-1b-lora-run-7</strong> at: <a href='https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3/runs/4b38689h' target=\"_blank\">https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3/runs/4b38689h</a><br> View project at: <a href='https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3' target=\"_blank\">https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250707_072551-4b38689h/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250707_075420-l6q8vmze</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3/runs/l6q8vmze' target=\"_blank\">gemma-1b-lora-run-8</a></strong> to <a href='https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3' target=\"_blank\">https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3/runs/l6q8vmze' target=\"_blank\">https://wandb.ai/architkohli-msit/dlp_nppe1_gemma_3/runs/l6q8vmze</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/7176 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a11962656ace429f856815ca0ed2a37a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/7176 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fedc50c579a446fcbcbd245097da6ca4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/7176 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bba84da617c42acaf2d90ee04811b48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to eval dataset:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad62513ba2ab4152a753e5966190bd7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bbb3f1238af4ce4ba975c25541bdaaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a2578c78b84acfb5fa27b1d1ff94fe"}},"metadata":{}}],"execution_count":145},{"cell_type":"code","source":"count_trainable_parameters(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:56:19.668325Z","iopub.execute_input":"2025-07-07T07:56:19.669088Z","iopub.status.idle":"2025-07-07T07:56:19.682606Z","shell.execute_reply.started":"2025-07-07T07:56:19.669032Z","shell.execute_reply":"2025-07-07T07:56:19.681901Z"}},"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"5843456"},"metadata":{}}],"execution_count":146},{"cell_type":"code","source":"import shutil\nfor i in range(1):\n    shutil.rmtree(f'/kaggle/working/checkpoints_run_4/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:57:00.343034Z","iopub.execute_input":"2025-07-07T07:57:00.343733Z","iopub.status.idle":"2025-07-07T07:57:00.347707Z","shell.execute_reply.started":"2025-07-07T07:57:00.343711Z","shell.execute_reply":"2025-07-07T07:57:00.346932Z"}},"outputs":[],"execution_count":149},{"cell_type":"code","source":"from transformers.trainer_utils import get_last_checkpoint\n\nlast_checkpoint = None\nif os.path.isdir(training_arguments.output_dir):\n    last_checkpoint = get_last_checkpoint(training_arguments.output_dir)\nif last_checkpoint is not None:\n    print(f\"Resuming training from checkpoint: {last_checkpoint}\")\n    trainer.train(resume_from_checkpoint=last_checkpoint)\nelse:\n    print(\"No checkpoint found, starting training from scratch.\")\n    trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:57:10.323466Z","iopub.execute_input":"2025-07-07T07:57:10.323992Z","iopub.status.idle":"2025-07-07T08:36:13.653610Z","shell.execute_reply.started":"2025-07-07T07:57:10.323969Z","shell.execute_reply":"2025-07-07T08:36:13.653034Z"}},"outputs":[{"name":"stdout","text":"No checkpoint found, starting training from scratch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='448' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [448/448 38:59, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>15</td>\n      <td>3.020700</td>\n      <td>1.828471</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.513300</td>\n      <td>1.506462</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.369900</td>\n      <td>1.371118</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.256700</td>\n      <td>1.315706</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.200100</td>\n      <td>1.267990</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.212900</td>\n      <td>1.234923</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>1.210600</td>\n      <td>1.217272</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.132100</td>\n      <td>1.192780</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>1.095000</td>\n      <td>1.178166</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.121700</td>\n      <td>1.165662</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>1.085100</td>\n      <td>1.150342</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.143400</td>\n      <td>1.134504</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>1.086800</td>\n      <td>1.126023</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.040200</td>\n      <td>1.112519</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>1.043700</td>\n      <td>1.107383</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.071200</td>\n      <td>1.096011</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>1.102400</td>\n      <td>1.093879</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.019700</td>\n      <td>1.083530</td>\n    </tr>\n    <tr>\n      <td>285</td>\n      <td>1.097300</td>\n      <td>1.075339</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.014200</td>\n      <td>1.072908</td>\n    </tr>\n    <tr>\n      <td>315</td>\n      <td>0.993800</td>\n      <td>1.061045</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.020500</td>\n      <td>1.061789</td>\n    </tr>\n    <tr>\n      <td>345</td>\n      <td>0.959000</td>\n      <td>1.057311</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.999700</td>\n      <td>1.053187</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.963500</td>\n      <td>1.045285</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>1.012000</td>\n      <td>1.043220</td>\n    </tr>\n    <tr>\n      <td>405</td>\n      <td>0.946700</td>\n      <td>1.034055</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.992600</td>\n      <td>1.036276</td>\n    </tr>\n    <tr>\n      <td>435</td>\n      <td>0.996200</td>\n      <td>1.026227</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":150},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/emoti-code-multi-script-emotion-classification-rel/competition_test.csv')\ntest_data[\"text\"] = test_data.apply(generate_val_prompt,axis=1) \ny_pred_test = predict_for_submission(test_data,model,tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T08:39:51.705366Z","iopub.execute_input":"2025-07-07T08:39:51.705817Z"}},"outputs":[{"name":"stderr","text":"Predicting Sentiments for Submission:  24%|██▍       | 571/2392 [06:21<20:03,  1.51it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"os.makedirs(\"submissions\", exist_ok=True)\ny_pred_test.to_csv(\"submissions/submission_1.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T11:41:31.225462Z","iopub.execute_input":"2025-07-06T11:41:31.225790Z","iopub.status.idle":"2025-07-06T11:41:31.239802Z","shell.execute_reply.started":"2025-07-06T11:41:31.225766Z","shell.execute_reply":"2025-07-06T11:41:31.239189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T11:41:37.968821Z","iopub.execute_input":"2025-07-06T11:41:37.969056Z","iopub.status.idle":"2025-07-06T11:41:37.980744Z","shell.execute_reply.started":"2025-07-06T11:41:37.969040Z","shell.execute_reply":"2025-07-06T11:41:37.979974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"shutil.rmtree('/kaggle/working/submissions')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T11:22:32.412558Z","iopub.execute_input":"2025-07-07T11:22:32.412818Z","iopub.status.idle":"2025-07-07T11:22:32.416666Z","shell.execute_reply.started":"2025-07-07T11:22:32.412801Z","shell.execute_reply":"2025-07-07T11:22:32.416106Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}